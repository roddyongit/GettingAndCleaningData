***ReadME file for script: run_analysis.R (Devoloped in RStudio Version 0.98.994 )***

Human Activity Recognition Using Smartphones Data set Version 2.0
Script (program name): run_analysis.R
Modified by: Coursera Student Name
Project: Getting and Cleaning Data
Email: myemail@gmail.com
Date: 08-22-2014

Original Source:
   Initially generated by: [www.smartlab.ws](www.smartlab.ws) (For more information about the original 
                                            data set contact: activityrecognition@smartlab.ws)

   Brief description of the study original conducted:

      The experiments have been carried out with a group of 30 volunteers within 
	  an age bracket of 19-48 years. Each person performed six activities 
	  WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING)
      wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded 
	  accelerometer and gyroscope, we captured 3-axial linear acceleration and 
	  3-axial angular velocity at a constant rate of 50Hz.   

***Note**: Only a subset of the original variables are used in the final results.*

	  


----------


**Purpose**: 

This Readme file was created to explain how the original 
Datasets from www.smartlab.ws was transformed using an
R Programming script name: run_analysis.R to do the following:

   1. Merge the training and the test sets to create one data set.
   2. Extract only the measurements on the mean and standard deviation for each measurement. 
   3. Use descriptive activity names to name the activities in the data set
   4. Appropriately label the data set with descriptive variable names. 
   5. Create tidy data set with the average of each variable for each activity and each subject. 
        (For this project only the variable names with mean() and std() were selected to 
	     generate the final tidy data set)   
	 


----------


**REQUIREMENTS TO RUN THE SCRIPT**:

1. The file run_analysis.R must be located in the current working directory

2. The source files should be downloaded and unzipped in the current working directory 
   where the run_analysis.R script will run
      Source files location:  <add link here >  
      
3. The file should be extracted to the working directory and should look like this:

           <workingDir>/UCI HAR Dataset          
				  Required file in this folder: 
					        features.txt
							activity_labels.txt (not required to run script, but needed as reference to
												 convert activity no to meaningful activity names)
		   <workingDir>/UCI HAR Dataset/test          
				  Required files in this folder: 
					        subject_test.txt
							      X_test.txt
								  y_test.txt
		   <workingDir>/UCI HAR Dataset/test          
				  Required files in this folder: 
					        subject_train.txt
							      X_train.txt
								  y_train.txt

Notes: The other sub-folders under UCI HAR Dataset directory are not required to run this script.
								  


----------


**FILES INCLUDED IN THE PROJECT:**

------------------------------------------------------------------
- run_analysis.R: R script to upload, transform and create the tidy data set
- CodeBook.md: Explanation of variables used in the final data set (names, description, unit of measure...)
- README.md: Explanation of how all pieces work together 
             script, source files and resulting data data sets)
   (The 3 files above can be found here: https://github.com/roddyongit/datacleaningproject)
- features.txt': List of all features or variable names for the study.
- X_train.txt: Training set - contains all the results of train the study: 561 variables.
- y_train.txt: Number of activity performed by the people that participated in the train study.
               There is one entry for each record in the X_train.txt file.   
- X_test.txt: Test set. contains all the results of the study: 561 variables.
- y_test.txt: Number of activity performed by the people that participated in the test study.
		      There is one entry for each record in the X_train.txt file.   
- subject_train.txt: Each row identifies the subject who performed the activity for each window sample.(24 out of 30 selected for train)
- subject_test.txt: Each row identifies the subject who performed the activity for each window sample.(6 out of 30 selected for test)
- activity_labels: Names of activities: From 1 to 6: ( WALKING , WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) 
 
------------------------------------------------------------------

**OUTPUT GENERATED BY THE SCRIPT:**

1. File: ExtractMeanAndStdOnly.txt as required in step 2 of the project
   (Extracts only the measurements on the mean and standard deviation for each measurement)
   - This file is only created and stored in the current working directory, but not submitted
     to github or coursera. It can be used for further analysis.
	 
2. File: AvgAllBySubjectActivityDataSet2.txt   (Data set uploaded to Coursera or second data set)
   (Step 5: Create tidy data set with the average of each variable for each activity and each subject.) - Each variable measurement was suffixed with "_colAVG" to make clear that they represent the average of the column (either mean or standard deviation).

------------------------------------------------------------------
**WALKING-THROUGH THE SCRIPT** 
(How the data was loaded, transformed and final tidy data set generated)

----------


 **Load required libraries to use ddply function**

 `library("plyr")`
    
 Load all required text files: Test, Train, Activities and features... using read.table
 i.e:   Load results of the study (Test or Train)...


    xTrain = read.table("UCI HAR Dataset/train/X_train.txt", header=FALSE)

**Load features description file: 561 variables from the study**

`fatures = read.table("UCI HAR Dataset/features.txt", header=FALSE) `
                
**Merge test and train study results**
     mergedTestAndTrain = rbind(xTrain, xTest)
        
**Add variable names from features.txt file to mergedTestAndTrain dataset**

This will change the non-descriptive variable names V1, V2, V3... to more meaningful variable names
		
`colnames(mergedTestAndTrain) <- features[,2] `
        
 **Merge subject from train and test files**

This will put in one dataset all the people that participated in the study. They were originally divided in 2 groups: test(30%) and train (70%)


    subjectAll = rbind(subjectTrain, subjectTest)
        

 **Merge activities from Y_train and Y_test files**

Combine all activity numbers from test and train into a single data set
In this case the row count will match the combined data set for test and train,making it possible to combined all together later.

`activityAll =  rbind(yTrain, yTest)` 

        
**Add columns "subject" and "activity" to the left of mergedTestAndTrain data set and change col. names to more meaningful names: "subject" and "activity" instead of "V1"**
        

      mergedTestAndTrain = cbind(subjectAll, activityAll, mergedTestAndTrain )
	  colnames(mergedTestAndTrain)[1] <- "subject"
      colnames(mergedTestAndTrain)[2] <- "activity"
       
**Project Requirement Part 3: Use descriptive activity names to name activities in data set**

Replace activity numbers with descriptive activity names (based on activity_labels file)
        

----------

  `mergedTestAndTrain$activity[mergedTestAndTrain$activity == 1]= "WALKING"`       `mergedTestAndTrain$activity[mergedTestAndTrain$activity == 2]= "WALKING_UPSTAIRS"`
  `mergedTestAndTrain$activity[mergedTestAndTrain$activity == 3]= "WALKING_DOWNSTAIRS"`
  `mergedTestAndTrain$activity[mergedTestAndTrain$activity == 4]= "SITTING" `  
  `mergedTestAndTrain$activity[mergedTestAndTrain$activity == 5]= "STANDING"`
  `mergedTestAndTrain$activity[mergedTestAndTrain$activity == 6]= "LAYING" `


**Project Requirement Step 1: Merges the training and test sets to create one data set.**
 Generates file TestAndTrainDataSet1.txt and stores it in the current working directory
 This file will not be uploaded to Coursera, it will only exist in the current working directory.


 ```
  write.table(mergedTestAndTrain, file = "TestAndTrainDataSet1.txt",      
         sep = ",", row.names=FALSE, quote=FALSE)
```


----------


        
 **Project requirement Part 2: Extracts only the measurements on the mean and standard deviation for each measurement.**
               
`stdAndMean = features[grepl("mean\\()",tolower(features$V2)) | grepl("std\\()",tolower(features$V2)),]`
`stdAndMeanVector = as.vector(stdAndMean$V2)   
        TestAndTrainMeanAndStd =  mergedTestAndTrain[,c("subject","activity",stdAndMeanVector)]`
    
 


----------

**Project Requirement Part 4: Appropriately labels the data set 
with descriptive variable names** 

Remove all "-", "()"

`tidyVarNames = gsub("-","",names(TestAndTrainMeanAndStd))
        tidyVarNames = gsub("\\()","",tidyVarNames)`
        
**Convert mean and std variable names to camel case naming convention and more meaningful**

`tidyVarNames = gsub("meanX","MeanXaxis",tidyVarNames)`
`        tidyVarNames = gsub("meanY","MeanYaxis",tidyVarNames)`
`        tidyVarNames = gsub("meanZ","MeanZaxis",tidyVarNames)`
`        tidyVarNames = gsub("stdX","StdXaxis",tidyVarNames)`
`        tidyVarNames = gsub("stdY","StdYaxis",tidyVarNames)`
`        tidyVarNames = gsub("stdZ","StdZaxis",tidyVarNames)`
`        tidyVarNames = gsub("mean","Mean",tidyVarNames)`
`        tidyVarNames = gsub("std","Std",tidyVarNames)        `
`        tidyVarNames = gsub("Acc","Acceleration",tidyVarNames)`    
`        tidyVarNames = gsub("Mag","Magnitude",tidyVarNames)   `   
`        tidyVarNames = gsub("Gyro","Gyroscope",tidyVarNames)  `   
`        tidyVarNames = gsub("BodyBody","Body",tidyVarNames)   `   


----------


 **Apply new tidy column names to data set**
 
 `colnames(TestAndTrainMeanAndStd) = tidyVarNames`
        
 Part 2 -- Extract only the measurements on the mean and std for each measurement.
Subset of the mean and std variables only. 
Generates file ExtractMeanAndStdOnly.txt and stores it in the current working directory
This file will not be uploaded to Coursera, it will only exist in the current working directory.

 `write.table(TestAndTrainMeanAndStd, file = "ExtractMeanAndStdOnly.txt",      
                    sep = ",", row.names=FALSE, quote=FALSE)`
    

**Calculate the average for all variables in the data set by subject and activity.**

`AvgAllBySubjectActivity <-ddply(TestAndTrainMeanAndStd,.(subject,activity),colwise(mean)`
        
****Append suffix "_colAVG" to all variables in final tidy data set****

  ` names(AvgAllBySubjectActivity) = paste(names (AvgAllBySubjectActivity),"_colAVG",sep="")`
  ` colnames(AvgAllBySubjectActivity)[1] <- "subject"` 
  ` colnames(AvgAllBySubjectActivity)[2] <- "activity"`



        
 Project Requirement Step 5: Creates a second independent tidy data set with the average of each activity and each subject
This file will be uploaded to Coursera. This is the final data set.

`write.table(AvgAllBySubjectActivity, file = "AvgAllBySubjectActivityDataSet2.txt",      
 sep = ",", row.names=FALSE, quote=FALSE)`
        




------------------------------------------------------------------
Other notes:

Naming convention used for data sets and variables: [camelCase](http://en.wikipedia.org/wiki/CamelCase)

----------


Measurement used: The details can be found in the CodeBoook.md in the 
github repository: https://github.com/roddyongit/datacleaningproject 


----------


			   
			   
